# Explore transformer network for SST

## Background
The transformer network is a sequence-to-sequence model that uses an attention mechanism to map the input sequence to the output sequence. It is a powerful model that can be used in many fields, such as machine translation, image captioning, and speech synthesis.

Text-to-speech (TTS) methods are widely used in many applications, such as voice assistants, voice chatbots, and voice-based user interfaces. 

## Aim of this project
- understanding the transformer network thoroughly
- explore the application of the transformer network in TTS
- explore in other real physics questions [perhaps].

## Materials
There are some materials to learn about the transformer network:

- [TRANSFORMERS FROM SCRATCH](https://peterbloem.nl/blog/transformers)
- [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)
- [Neural Speech Synthesis with Transformer Network](https://arxiv.org/abs/1809.08895)

And the following are some ready-to-use code or tools:

- [Generate molecular configuration-alanine dipeptide](https://colab.research.google.com/drive/1cj1VVwFILP7cJwX0BA4RKvUrsVzJyS-S?usp=sharing)
- [Parakeet入门](https://aistudio.baidu.com/aistudio/projectdetail/639029)：使用WaveFlow和Transformer TTS训练语音合成模型
- [SoftVC VITS Singing Voice Conversion](https://github.com/svc-develop-team/so-vits-svc), The singing voice conversion model uses SoftVC content encoder to extract source audio speech features.
- [Jukebox](https://openai.com/research/jukebox), a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. 